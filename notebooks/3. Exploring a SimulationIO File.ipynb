{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring a SimulationIO File\n",
    "\n",
    "In this file you will learn to explore a SimulationIO file using the SimulationIO API.\n",
    "\n",
    "As you read through the file, try evaluating the code by clicking on the cell and pressing `shift+enter` to see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a file\n",
    "\n",
    "First we need to create a file to explore. We'll use the static tov star. Here we show off some of the the IPython notebooks cell magic to evaluate a bash script. (You only need to do this once.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "/usr/local/bin/sio-convert-carpet-output \\\n",
    "./static-tov-cell.s5 \\\n",
    "./data/static_tov_cell/output-0000/static_tov_cell_centred/*.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from a File\n",
    "\n",
    "To read from the file, we import the SimulationIO API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pysimulationio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top-level object for a SimulationIO file is a `project`, which may in principle contain the output of many simulations. For our purposes, however, it will contain only one.\n",
    "\n",
    "We can load the project by using the `readProject` method. This method returns a `project` object, which is the root of the SimulationIO graph, and a `file_handle` object, which can be used to access the SimulationIO hdf5 file directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project,file_handle = pysimulationio.readProject('static-tov-cell.s5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A project may have many different spacetime manifolds. This simulation has only one of them. We can access it via `project.manifolds`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manifold = project.manifolds.values()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A configuration is output associated with a particular collection of variables. In our case, it's just the timestep and time level (for local timestepping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for configuration_name in project.configurations.iterkeys():\n",
    "    print configuration_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `global` configuration is always present and may or may not contain any information. We want the `iteration=0` configuration. The configurations are stored in a dictionary (python implementation of a hash table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "configuration_name = 'iteration.0000000000-timelevel.0'\n",
    "configuration = project.configurations[configuration_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, you can access the coordinate systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for cs in project.coordinatesystems.iterkeys():\n",
    "    print cs\n",
    "# Lock is required because internally these are weak pointers\n",
    "coordinate_system = configuration.coordinatesystems.values()[0].lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretizations and subdiscretizations\n",
    "\n",
    "A `discretization` is what it sounds like, a discrete approximation of a manifold. On an AMR-type grid, discretizations correspond to refinement levels.\n",
    "\n",
    "A `subdiscretization` is a relationship *between* two discretizations. It tells us, for example, if refinement levels are offset from each other, and by how many cells. And it tells us how much more refined the finer region is than the coarser.\n",
    "\n",
    "First let's find the root discretization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in manifold.discretizations.itervalues():\n",
    "    if d.configuration.name == configuration_name and len(d.parent_discretizations) == 0:\n",
    "        root_discretization = d\n",
    "print root_discretization.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's explore the discretization, subdiscretization relationship by following the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "discretizations = [root_discretization]\n",
    "subdiscretizations = []\n",
    "d = root_discretization\n",
    "while True:\n",
    "    sds = d.child_discretizations.values()\n",
    "    if not sds: # no children? There are no finer levels\n",
    "        break\n",
    "    # There should only be one finer level\n",
    "    sd = sds[0].lock() # again we need to do lock\n",
    "    d = sd.child_discretization\n",
    "    discretizations.append(d)\n",
    "    subdiscretizations.append(sd)\n",
    "print \"Discretizations:\"\n",
    "for d in discretizations:\n",
    "    print d.name\n",
    "print \"Subdiscretizations:\"\n",
    "for sd in subdiscretizations:\n",
    "    print sd.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each discretization is broken into \"blocks.\" The blocks may be MPI threads or simply spatial separated refinement regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "discretization = discretizations[1]\n",
    "blocks = list(discretization.discretizationblocks.itervalues())\n",
    "print \"Our blocks are:\"\n",
    "for block in blocks:\n",
    "    print block.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each block has a `region` attribute and an `active` attribute. The `region` tells us the shape and positions of all possible data contained in a block. The `active` attribute tells us only the evolved data. These are separate because regions on different processors have \"inactive\" regions called `ghost zones`. \n",
    "\n",
    "Let's take a look. If you print these attributes they tell the indexes of the cells or vertices where the regions are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "block = blocks[0]\n",
    "print \"The active region has indexes: {}\".format(block.active)\n",
    "print \"The total region has indexes: {}\".format(block.region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fields and Discrete Fields\n",
    "\n",
    "So we can explore the discretization of the manifold... But how do we actually get data out of it? For that we need to explore `fields`, which correspond to variables like density, pressure, or the metric, and their discrete analogues, `discretefields`.\n",
    "\n",
    "Fields are project-local, not manifold local. Let's list them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in project.fields.iterkeys():\n",
    "    print f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, fields obey the same naming convention as Cactus. (No surprise, they came from Cactus!)\n",
    "\n",
    "Let's try and dig down to a single field, say the density, and extract some information about it. We'll need to dig down through a few links in the SimulationIO metadata graph.\n",
    "\n",
    "First we grab the field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "field = project.fields['HYDROBASE::rho']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A field has discrete analogoues, each one corresponding to a discretization of the manifold. Let's print them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for df in field.discretefields.iterkeys():\n",
    "    print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's get the discrete field corresponding to the discretization we looked at earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "discretefield = None\n",
    "for df in field.discretefields.itervalues():\n",
    "    if discretization.name in df.name:\n",
    "        discretefield = df\n",
    "        break\n",
    "print \"Our discrete field name is:\\n{}\".format(discretefield.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each discrete field has discrete field blocks, which correspond to the blocks we found earlier when looking at discretizations. Let's list them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dfb in discretefield.discretefieldblocks.iterkeys():\n",
    "    print dfb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do those look familiar? They should. They're the same names as the discretization blocks. Let's get the one that corresponded to our block from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "discretefieldblock = None\n",
    "for dfb in discretefield.discretefieldblocks.itervalues():\n",
    "    if dfb.name == block.name:\n",
    "        discretefieldblock = dfb\n",
    "        break\n",
    "print \"Our discrete field block is: {}\".format(discretefieldblock.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components\n",
    "\n",
    "Some fields are a collection of variables, for instance the metric tensor or a velocity vector. SimulationIO treats these as `components`. The field we chose, the density, doesn't have more than one. But it's worth knowing about them. Let's see what it looks like for our scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in discretefieldblock.discretefieldblockcomponents.iterkeys():\n",
    "    print c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a scalar, so that makes sense. Let's access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discretefieldblockcomponent = list(discretefieldblock.discretefieldblockcomponents.itervalues())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "\n",
    "So now let's read the data. Unfortunately, there are a few steps here. We have to create an hdf5 dataset object and read this dataset into a numpy array. Then we have to reshape it to the proper shape. The whole procedure goes something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # numpy as a wrapper for fortran arrays\n",
    "dataset = discretefieldblockcomponent.getData_DataSet()\n",
    "region = block.region # remember our block from earlier?\n",
    "# includes ghost zones\n",
    "data = np.array(dataset.read_double()).reshape(region.shape())\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the data is a flattened 1D array. Hence we need to reshape it to the proper shape.\n",
    "\n",
    "We can plot a 1D or 2D slice of this little block of data. We don't even need yt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "%matplotlib inline\n",
    "# this makes a 2D plot\n",
    "plt.pcolor(data[80,...,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and this makes a 1D plot\n",
    "plt.plot(data[80,...,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The region of the space we chose to look at was totally empty. This is just noise. But it's still a useful exercise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in via h5py\n",
    "\n",
    "Those of you familiar with Python may have noticed that we used a different syntax than the one used for `h5py`, Python's hdf5 wrapper. Unfortunately, `h5py` is currently not integrated well with `PySimulationIO`. However, we can still use it if need be by accessing file paths. It's a bit clunky though.\n",
    "\n",
    "To make things work, we ask for the \"path\" through the hdf5 file to the dataset we're interested in and the name of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = discretefieldblockcomponent.getPath()\n",
    "name = discretefieldblockcomponent.getName()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can feed the path and name into h5py and use it to read the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py # import the library\n",
    "with h5py.File('static-tov-cell.s5','r') as f:\n",
    "# We use the \":\" syntax as a trick to copy the dataset\n",
    "# into a numpy array\n",
    "    data_h5py = f[path][name][:]\n",
    "print data_h5py.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait... something is wrong! The shapes are different!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"h5py gives {}\".format(data_h5py.shape)\n",
    "print \"pysimulationio gives {}\".format(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're permuted! This is a quirk of the metadata conventions in `SimulationIO`. Python uses `C`-type (row major) ordering of the arrays, but the Cactus and SimulationIO output files use `Fortran`-type (column major) ordering. You can get around it by reshaping the array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_h5py = data_h5py.reshape(region.shape(),\n",
    "                              \n",
    "                              order=\"Fortran\")\n",
    "print data_h5py.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "So, we've opened a `SimulationIO` file and dug into it to find properties of the discretization of the spacetime manifold and extracted some data. \n",
    "\n",
    "It's also possible to **create** `SimulationIO` files using the `pysimulationio` API. But that is a topic for another time.\n",
    "\n",
    "If you want more examples on how to use the API, check out the `pysimulationio-examples` directory. It should be in your home directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
